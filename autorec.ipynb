{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Stuff:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our Stuff:\n",
    "from models.AutoRecBase import AutoRecBase\n",
    "from models.VarAutoRec import VarAutoRec\n",
    "from models.MF import MF\n",
    "\n",
    "\n",
    "from scripts.get_data import download_2_data_sets, ratings_to_train_test, ratings_to_train_test_u\n",
    "from scripts.get_2_other_data import get_2_other_datasets, secondary_to_train_test, secondary_to_train_test_u\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.loading_utils import load_model, save_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Visualization Stuff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec - AutoEncoders Meet Collaborative Filtering - PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"toc\"></a>\n",
    "## Table of Content\n",
    "1. [Introduction](#introduction)\n",
    "1. [Conclusions](#conclusions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"introduction\"></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will review a collaborative filtering approach using autoencoders, as suggested by Sedhain et al, in their 2015 paper \"AutoRec: Autoencoders Meet Collaborative Filtering\".\n",
    "\n",
    "We will then introduce several improvements and asses them.\n",
    "\n",
    "[Table of content](#toc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "is_default_dataset = True\n",
    "if is_default_dataset:\n",
    "    download_2_data_sets()\n",
    "else:\n",
    "    get_2_other_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if is_default_dataset:\n",
    "    train_loader, val_loader = ratings_to_train_test(1,0, 1,10)\n",
    "    mf_train_loader, mf_val_loader =  ratings_to_train_test_u(dataset_size=1,\n",
    "                                                              validation_partition=0,\n",
    "                                                              train_partition=1,\n",
    "                                                              batch_size=10)\n",
    "else:\n",
    "    train_loader, val_loader = secondary_to_train_test(1,0, 1,10)\n",
    "    mf_train_loader, mf_val_loader =  secondary_to_train_test_u(dataset_size=1,\n",
    "                                                                validation_partition=0,\n",
    "                                                                train_partition=1,\n",
    "                                                                batch_size=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to:  [TensorBoard](http://localhost:6006)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "models_dict = {} # (model,ephoc,lr): loss\n",
    "models_state = {} # (model,ephoc,lr): model.state_dict()\n",
    "models = [\n",
    "    # AutoRecBase,\n",
    "    # VarAutoRec,\n",
    "    MF\n",
    "]\n",
    "lrs = [0.001,0.002,0.004,0.01]\n",
    "activations = [nn.PReLU, nn.Sigmoid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sanity check:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3., 3., 3., 3., 4., 3., 4., 5., 5.])\n",
      "tensor(1)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([2294, 3186, 1566,  588, 1907,  783, 1836,  150,    1, 1962])\n",
      "tensor([4, 4, 4, 4, 4, 4, 5, 5, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "for x, y, m in val_loader:\n",
    "    print(x[:,0])\n",
    "    break\n",
    "for x, y, m in mf_val_loader:\n",
    "    print(x[0])\n",
    "    break\n",
    "for x, y, r in mf_train_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(r)\n",
    "    break\n",
    "# model(x)[:,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n",
      "Number of items: 3706\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users: {len(val_loader.dataset)}\")\n",
    "print(f\"Number of items: {len(val_loader.dataset[0][1])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Datasets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "number_of_items = len(val_loader.dataset)\n",
    "number_of_users = len(val_loader.dataset[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the original paper:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "latent_dims = [10, 20, 40, 80, 100, 200, 300, 400, 500]\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 100, 1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type      | Params\n",
      "------------------------------------------------\n",
      "0 | embedding_user_mf | Embedding | 37.1 K\n",
      "1 | embedding_item_mf | Embedding | 60.4 K\n",
      "2 | l_0               | Linear    | 11    \n",
      "3 | loss_func         | L1Loss    | 0     \n",
      "------------------------------------------------\n",
      "97.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "97.5 K    Total params\n",
      "0.390     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df8555e555244c10b2ecf86ceb23c67b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b20c8a16a45244ad873e86f7e2926c53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type      | Params\n",
      "------------------------------------------------\n",
      "0 | embedding_user_mf | Embedding | 37.1 K\n",
      "1 | embedding_item_mf | Embedding | 60.4 K\n",
      "2 | l_0               | Linear    | 11    \n",
      "3 | loss_func         | L1Loss    | 0     \n",
      "------------------------------------------------\n",
      "97.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "97.5 K    Total params\n",
      "0.390     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d14b5cdc7b0f491395e861a4ba744f12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8113ff3c2df047dc8e8a470a7abc8576"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "should_train = True\n",
    "model_paths = []\n",
    "if should_train:\n",
    "    for model_class in models:\n",
    "        for activation in activations:\n",
    "            for lr in lrs:\n",
    "                for latent in latent_dims:\n",
    "                    for λ in lambdas:\n",
    "                        model = model_class(number_of_items=number_of_items,\n",
    "                                            num_of_users=number_of_users,\n",
    "                                            hidden_size=latent,\n",
    "                                            activation_function_1=activation,\n",
    "                                            activation_function_2=activation,\n",
    "                                            loss=nn.MSELoss(reduction='none'),\n",
    "                                            λ=λ,\n",
    "                                            lr=lr)\n",
    "                        # training\n",
    "                        trainer = pl.Trainer(gpus=0, max_epochs=10)\n",
    "                        if type(model).__name__ == \"MF\":\n",
    "                            trainer.fit(model,mf_train_loader, mf_val_loader)\n",
    "                        else:\n",
    "                            trainer.fit(model,train_loader, val_loader)\n",
    "\n",
    "                        model_path = save_model(model_class=model_class,\n",
    "                                   trainer=trainer,\n",
    "                                   activation=activation,\n",
    "                                   hidden_size=latent,\n",
    "                                   lr=lr,\n",
    "                                   λ=λ,\n",
    "                                   is_default_dataset=is_default_dataset)\n",
    "                        model_paths.append(model_path)\n",
    "        #                 break\n",
    "        #             break\n",
    "        #         break\n",
    "        #     break\n",
    "        # break\n",
    "print(model_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_eval_dict = {}\n",
    "Ks = [5, 10]\n",
    "i = 0\n",
    "\n",
    "for model_class in models:\n",
    "    for activation in activations:\n",
    "        for lr in lrs:\n",
    "            for latent in latent_dims:\n",
    "                for λ in lambdas:\n",
    "                    model = load_model(model_class=model_class,\n",
    "                                       activation=activation,\n",
    "                                       hidden_size=latent,\n",
    "                                       lr=lr,\n",
    "                                       λ=λ,\n",
    "                                       is_default_dataset=is_default_dataset)\n",
    "                    for K in Ks:\n",
    "                        (hits, ndcgs, mrrs) = evaluate_model(model, test_loader=val_loader, K=K)\n",
    "                        models_eval_dict[f\"row_{i}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"HR\", np.mean(hits)]\n",
    "                        models_eval_dict[f\"row_{i+1}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"NDCG\",np.mean(ndcgs)]\n",
    "                        models_eval_dict[f\"row_{i+2}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"MRR\",np.mean(mrrs)]\n",
    "                        i += 3\n",
    "    #                     break\n",
    "    #                 break\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"model\", \"activation\", \"latent_dim\", \"lambda\", \"lr\",\"topk\",\"metric\",\"score\"]\n",
    "eval_df = pd.DataFrame.from_dict(models_eval_dict, orient='index', columns=columns)\n",
    "eval_df.to_csv(\"obj/eval_df\", sep='\\t')\n",
    "\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}