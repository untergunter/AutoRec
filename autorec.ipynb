{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Stuff:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our Stuff:\n",
    "from models.AutoRecBase import AutoRecBase\n",
    "from models.VarAutoRec import VarAutoRec\n",
    "from models.NMF import NMF\n",
    "\n",
    "\n",
    "from scripts.get_data import download_2_data_sets, ratings_to_train_test\n",
    "from scripts.get_2_other_data import get_2_other_datasets, secondary_to_train_test\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.loading_utils import load_model, save_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Visualization Stuff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec - AutoEncoders Meet Collaborative Filtering - PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"toc\"></a>\n",
    "## Table of Content\n",
    "1. [Introduction](#introduction)\n",
    "1. [Conclusions](#conclusions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"introduction\"></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will review a collaborative filtering approach using autoencoders, as suggested by Sedhain et al, in their 2015 paper \"AutoRec: Autoencoders Meet Collaborative Filtering\".\n",
    "\n",
    "We will then introduce several improvements and asses them.\n",
    "\n",
    "[Table of content](#toc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/odedgolden/Developer/AutoRec/scripts/get_data.py:39: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_table(\n"
     ]
    }
   ],
   "source": [
    "is_default_dataset = True\n",
    "if is_default_dataset:\n",
    "    download_2_data_sets()\n",
    "else:\n",
    "    get_2_other_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if is_default_dataset:\n",
    "    train_loader, val_loader = ratings_to_train_test(1,0, 1,10)\n",
    "else:\n",
    "    train_loader, val_loader = secondary_to_train_test(1,0, 1,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to:  [TensorBoard](http://localhost:6006)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "models_dict = {} # (model,ephoc,lr): loss\n",
    "models_state = {} # (model,ephoc,lr): model.state_dict()\n",
    "models = [AutoRecBase, VarAutoRec, NMF]\n",
    "lrs = [0.0005,0.001,0.002,0.004]\n",
    "activations = [nn.PReLU. nn.Sigmoid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the original paper:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "latent_dims = [10, 20, 40, 80, 100, 200, 300, 400, 500]\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 100, 1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | encoder   | Linear  | 92.7 K\n",
      "1 | act_1     | PReLU   | 1     \n",
      "2 | decoder   | Linear  | 96.4 K\n",
      "3 | act_2     | PReLU   | 1     \n",
      "4 | loss_func | MSELoss | 0     \n",
      "--------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2f255e5c3bd45b88f8b363af6e178f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6207848489354c4eb59759332fbd58b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f780bcef411491b8cbcd4cccef5d201"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fd18bc545254cbcbbd2e73149912ace"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db05ddb1c744437696a92a4d03c80ec5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "947b8000eaa7491f83822d379c8aac04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2863d340f544dbda4f1dca7185ef590"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c8f3a18f1f04d1b8ebce7718e913ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "016ddee5515c4ea291f570b7936bfd58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84acdb793cc44f60b2b0bcccba3044af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "768321dd6cfd4872836aee81b73ed85c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a72edfc36f54c5baea54f210eeea6ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'obj/AutoRecBase_0.001_10_model_dict.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(gpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     10\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model,train_loader, val_loader)\n\u001B[0;32m---> 11\u001B[0m \u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlambdas\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlatent_dims\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/AutoRec/utils/loading_utils.py:16\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(model, lr, hidden_size)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msave_model\u001B[39m(model, lr, hidden_size):\n\u001B[0;32m---> 16\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mobj/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlr\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mhidden_size\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_model_dict.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:376\u001B[0m, in \u001B[0;36msave\u001B[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \n\u001B[1;32m    342\u001B[0m \u001B[38;5;124;03mSaves an object to a disk file.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;124;03m    >>> torch.save(x, buffer)\u001B[39;00m\n\u001B[1;32m    373\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    374\u001B[0m _check_dill_version(pickle_module)\n\u001B[0;32m--> 376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _open_zipfile_writer(opened_file) \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:230\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 230\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:211\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 211\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'obj/AutoRecBase_0.001_10_model_dict.pt'"
     ]
    }
   ],
   "source": [
    "for model_class in models:\n",
    "    for activation in activations:\n",
    "        for lr in lrs:\n",
    "            for latent in latent_dims:\n",
    "                for λ in lambdas:\n",
    "                    model = model_class(number_of_items=3706,\n",
    "                                        hidden_size=25,\n",
    "                                        activation_function_1=activation,\n",
    "                                        activation_function_2=activation,\n",
    "                                        loss=nn.MSELoss(reduction='none'),\n",
    "                                        λ=λ,\n",
    "                                        lr=lr)\n",
    "                    # training\n",
    "                    trainer = pl.Trainer(gpus=0,max_epochs=10)\n",
    "                    trainer.fit(model,train_loader, val_loader)\n",
    "                    save_model(model, activation=activation,  hidden_size=latent_dims[0], lr=lambdas[0], λ=λ, is_default_dataset=is_default_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_eval_dict = {}\n",
    "Ks = [5, 10]\n",
    "i = 0\n",
    "\n",
    "for model_class in models:\n",
    "    for activation in activations:\n",
    "        for lr in lrs:\n",
    "            for latent in latent_dims:\n",
    "                for λ in lambdas:\n",
    "                    model = model_class()\n",
    "                    model = load_model(model=model,\n",
    "                                       activation=activation, \n",
    "                                       hidden_size=latent_dims[0], \n",
    "                                       lr=lambdas[0], \n",
    "                                       λ=λ, \n",
    "                                       is_default_dataset=is_default_dataset)\n",
    "                    # model.eval()\n",
    "                    for K in Ks:\n",
    "                        (hits, ndcgs, mrrs) = evaluate_model(model, val_loader, K)\n",
    "                        models_eval_dict[f\"row_{i}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"HR\", np.mean(hits)]\n",
    "                        models_eval_dict[f\"row_{i+1}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"NDCG\",np.mean(ndcgs)]\n",
    "                        models_eval_dict[f\"row_{i+2}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"MRR\",np.mean(mrrs)]\n",
    "                        i += 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"model\", \"activation\", \"latent_dim\", \"lambda\", \"lr\",\"topk\",\"metric\",\"score\"]\n",
    "eval_df = pd.DataFrame.from_dict(models_eval_dict, orient='index', columns=columns)\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(60, 20)\n",
    "\n",
    "for i, metric in enumerate(['HR', 'NDCG', 'MRR']):\n",
    "    sns.barplot(data=eval_df[eval_df[\"metric\"] == metric], x=\"model\", y=\"score\", hue=\"topk\", ax=axs[i], orient='v').set(title=metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}