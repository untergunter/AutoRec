{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "module() takes at most 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Our Stuff:\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mAutoRecBase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoRecBase\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mVarAutoRec\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VarAutoRec\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mNMF\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NMF\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mget_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m download_2_data_sets, ratings_to_train_test\n",
      "File \u001B[0;32m~/Developer/AutoRec/models/VarAutoRec.py:7\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpytorch_lightning\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpl\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoRecBase\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mVarAutoRec\u001B[39;00m(AutoRecBase):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m      9\u001B[0m                  number_of_items: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m     10\u001B[0m                  hidden_size: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m     11\u001B[0m                  activation_function_1,\n\u001B[1;32m     12\u001B[0m                  activation_function_2,\n\u001B[1;32m     13\u001B[0m                  loss):\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28msuper\u001B[39m(VarAutoRec, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(number_of_items\u001B[38;5;241m=\u001B[39mnumber_of_items,\n\u001B[1;32m     15\u001B[0m                                          hidden_size\u001B[38;5;241m=\u001B[39mhidden_size,\n\u001B[1;32m     16\u001B[0m                                          activation_function_1\u001B[38;5;241m=\u001B[39mactivation_function_1,\n\u001B[1;32m     17\u001B[0m                                          activation_function_2\u001B[38;5;241m=\u001B[39mactivation_function_2,\n\u001B[1;32m     18\u001B[0m                                          loss\u001B[38;5;241m=\u001B[39mloss)\n",
      "\u001B[0;31mTypeError\u001B[0m: module() takes at most 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "# General Stuff:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our Stuff:\n",
    "from models.AutoRecBase import AutoRecBase\n",
    "from models.VarAutoRec import VarAutoRec\n",
    "from models.NMF import NMF\n",
    "\n",
    "\n",
    "from scripts.get_data import download_2_data_sets, ratings_to_train_test\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.loading_utils import load_model, save_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Visualization Stuff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec - AutoEncoders Meet Collaborative Filtering - PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"toc\"></a>\n",
    "## Table of Content\n",
    "1. [Introduction](#introduction)\n",
    "1. [Conclusions](#conclusions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"introduction\"></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will review a collaborative filtering approach using autoencoders, as suggested by Sedhain et al, in their 2015 paper \"AutoRec: Autoencoders Meet Collaborative Filtering\".\n",
    "\n",
    "We will then introduce several improvements and asses them.\n",
    "\n",
    "[Table of content](#toc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/odedgolden/Developer/AutoRec/scripts/get_data.py:39: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_table(\n"
     ]
    }
   ],
   "source": [
    "download_2_data_sets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_loader, val_loader = ratings_to_train_test(1,0, 1,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to:  [TensorBoard](http://localhost:6006)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_dict = {} # (model,ephoc,lr): loss\n",
    "models_state = {} # (model,ephoc,lr): model.state_dict()\n",
    "models = [AutoRecBase, VarAutoRec, NMF]\n",
    "lrs = [0.0005,0.001,0.002,0.004]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the original paper:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dims = [10, 20, 40, 80, 100, 200, 300, 400, 500]\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 100, 1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | encoder   | Linear  | 92.7 K\n",
      "1 | act_1     | PReLU   | 1     \n",
      "2 | decoder   | Linear  | 96.4 K\n",
      "3 | act_2     | PReLU   | 1     \n",
      "4 | loss_func | MSELoss | 0     \n",
      "--------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "705215ac216345948d074704a38ad3f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "beddcd6918574b129652b7b2bea1488f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc447351de0f46ecbe33a1c7b91209d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d62186ac344b5982e050ac240bf9ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "354793b88f3c4deeb6178f89f12c8358"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f63cff4efedf44e49d382d9fb9839ff4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ac3fc92305447f7bee52011ce854db3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ac4565073114ea9936775ce6137080d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fee9404c04943eca4ad86d3b695d5e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0336a7861eb9430abfdf011af7d430c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0b88a22e09a49c3885496372b03e4ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45a3dd371f76411f9a44b16ad252d920"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoRecBase(number_of_items=3706,\n",
    "                    hidden_size=25,\n",
    "                    activation_function_1=nn.PReLU,\n",
    "                    activation_function_2=nn.PReLU,\n",
    "                    loss=nn.MSELoss,\n",
    "                    lr=lambdas[0])\n",
    "# training\n",
    "trainer = pl.Trainer(gpus=0,max_epochs=10)\n",
    "trainer.fit(model,train_loader, val_loader)\n",
    "save_model(model, lr=lambdas[0], hidden_size=latent_dims[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_eval_dict = {}\n",
    "Ks = [5, 10]\n",
    "i = 0\n",
    "\n",
    "for model_class in models:\n",
    "    for lr in lrs:\n",
    "        model = model_class()\n",
    "        model = load_model(model, lr=lr, hidden_size=latent_dims[0])\n",
    "        model.eval()\n",
    "        for K in Ks:\n",
    "            (hits, ndcgs, mrrs) = evaluate_model(model, val_loader, K)\n",
    "            models_eval_dict[f\"row_{i}\"] = [type(model).__name__, K, \"HR\", np.mean(hits)]\n",
    "            models_eval_dict[f\"row_{i+1}\"] = [type(model).__name__, K, \"NDCG\",np.mean(ndcgs)]\n",
    "            models_eval_dict[f\"row_{i+2}\"] = [type(model).__name__, K, \"MRR\",np.mean(mrrs)]\n",
    "            i += 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"model\",\"topk\",\"metric\",\"score\"]\n",
    "eval_df = pd.DataFrame.from_dict(models_eval_dict, orient='index', columns=columns)\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(60, 20)\n",
    "\n",
    "for i, metric in enumerate(['HR', 'NDCG', 'MRR']):\n",
    "    sns.barplot(data=eval_df[eval_df[\"metric\"] == metric], x=\"model\", y=\"score\", hue=\"topk\", ax=axs[i], orient='v').set(title=metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}