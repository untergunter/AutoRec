{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Stuff:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our Stuff:\n",
    "from models.AutoRecBase import AutoRecBase\n",
    "from models.VarAutoRec import VarAutoRec\n",
    "from models.NMF import NMF\n",
    "\n",
    "\n",
    "from scripts.get_data import download_2_data_sets, ratings_to_train_test\n",
    "from scripts.get_2_other_data import get_2_other_datasets, secondary_to_train_test\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.loading_utils import load_model, save_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Visualization Stuff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec - AutoEncoders Meet Collaborative Filtering - PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"toc\"></a>\n",
    "## Table of Content\n",
    "1. [Introduction](#introduction)\n",
    "1. [Conclusions](#conclusions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"introduction\"></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will review a collaborative filtering approach using autoencoders, as suggested by Sedhain et al, in their 2015 paper \"AutoRec: Autoencoders Meet Collaborative Filtering\".\n",
    "\n",
    "We will then introduce several improvements and asses them.\n",
    "\n",
    "[Table of content](#toc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "is_default_dataset = True\n",
    "if is_default_dataset:\n",
    "    download_2_data_sets()\n",
    "else:\n",
    "    get_2_other_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "if is_default_dataset:\n",
    "    train_loader, val_loader = ratings_to_train_test(1,0, 1,10)\n",
    "else:\n",
    "    train_loader, val_loader = secondary_to_train_test(1,0, 1,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-8584254d511e6d23\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-8584254d511e6d23\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to:  [TensorBoard](http://localhost:6006)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "models_dict = {} # (model,ephoc,lr): loss\n",
    "models_state = {} # (model,ephoc,lr): model.state_dict()\n",
    "models = [AutoRecBase, VarAutoRec, NMF]\n",
    "lrs = [0.0005,0.001,0.002,0.004]\n",
    "activations = [nn.PReLU, nn.Sigmoid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the original paper:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "latent_dims = [10, 20, 40, 80, 100, 200, 300, 400, 500]\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 100, 1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "should_train = False\n",
    "if should_train:\n",
    "    for model_class in models:\n",
    "        for activation in activations:\n",
    "            for lr in lrs:\n",
    "                for latent in latent_dims:\n",
    "                    for λ in lambdas:\n",
    "                        model = model_class(number_of_items=3706,\n",
    "                                            hidden_size=25,\n",
    "                                            activation_function_1=activation,\n",
    "                                            activation_function_2=activation,\n",
    "                                            loss=nn.MSELoss(reduction='none'),\n",
    "                                            λ=λ,\n",
    "                                            lr=lr)\n",
    "                        # training\n",
    "                        trainer = pl.Trainer(gpus=0,max_epochs=10)\n",
    "                        trainer.fit(model,train_loader, val_loader)\n",
    "                        save_model(model=model,\n",
    "                                   trainer=trainer,\n",
    "                                   activation=activation,\n",
    "                                   hidden_size=latent,\n",
    "                                   lr=lr,\n",
    "                                   λ=λ,\n",
    "                                   is_default_dataset=is_default_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [20]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# model.eval()\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m K \u001B[38;5;129;01min\u001B[39;00m Ks:\n\u001B[0;32m---> 25\u001B[0m     (hits, ndcgs, mrrs) \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mK\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     models_eval_dict[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, activation, latent, λ, lr, K, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHR\u001B[39m\u001B[38;5;124m\"\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(hits)]\n\u001B[1;32m     27\u001B[0m     models_eval_dict[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, activation, latent, λ, lr, K, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNDCG\u001B[39m\u001B[38;5;124m\"\u001B[39m,np\u001B[38;5;241m.\u001B[39mmean(ndcgs)]\n",
      "File \u001B[0;32m~/Developer/AutoRec/utils/evaluate.py:14\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model, test_loader, K)\u001B[0m\n\u001B[1;32m     11\u001B[0m hits, ndcgs, mrrs \u001B[38;5;241m=\u001B[39m [],[],[]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m user, item, rate \u001B[38;5;129;01min\u001B[39;00m test_loader:\n\u001B[0;32m---> 14\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mdetach())\n\u001B[1;32m     16\u001B[0m     (hr, ndcg, mrr) \u001B[38;5;241m=\u001B[39m eval_one_rating(predictions[:K])\n\u001B[1;32m     18\u001B[0m     hits\u001B[38;5;241m.\u001B[39mappend(hr)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "models_eval_dict = {}\n",
    "Ks = [5, 10]\n",
    "i = 0\n",
    "\n",
    "for model_class in models:\n",
    "    for activation in activations:\n",
    "        for lr in lrs:\n",
    "            for latent in latent_dims:\n",
    "                for λ in lambdas:\n",
    "                    model = model_class(number_of_items=3706,\n",
    "                                        hidden_size=25,\n",
    "                                        activation_function_1=activation,\n",
    "                                        activation_function_2=activation,\n",
    "                                        loss=nn.MSELoss(reduction='none'),\n",
    "                                        λ=λ,\n",
    "                                        lr=lr)\n",
    "                    model = load_model(model=model,\n",
    "                                       activation=activation,\n",
    "                                       hidden_size=latent,\n",
    "                                       lr=lr,\n",
    "                                       λ=λ,\n",
    "                                       is_default_dataset=is_default_dataset)\n",
    "                    # model.eval()\n",
    "                    for K in Ks:\n",
    "                        (hits, ndcgs, mrrs) = evaluate_model(model, test_loader=val_loader, K=K)\n",
    "                        models_eval_dict[f\"row_{i}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"HR\", np.mean(hits)]\n",
    "                        models_eval_dict[f\"row_{i+1}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"NDCG\",np.mean(ndcgs)]\n",
    "                        models_eval_dict[f\"row_{i+2}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"MRR\",np.mean(mrrs)]\n",
    "                        i += 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"model\", \"activation\", \"latent_dim\", \"lambda\", \"lr\",\"topk\",\"metric\",\"score\"]\n",
    "eval_df = pd.DataFrame.from_dict(models_eval_dict, orient='index', columns=columns)\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(60, 20)\n",
    "\n",
    "for i, metric in enumerate(['HR', 'NDCG', 'MRR']):\n",
    "    sns.barplot(data=eval_df[eval_df[\"metric\"] == metric], x=\"model\", y=\"score\", hue=\"topk\", ax=axs[i], orient='v').set(title=metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}