{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Stuff:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our Stuff:\n",
    "from models.AutoRecBase import AutoRecBase\n",
    "from models.VarAutoRec import VarAutoRec\n",
    "from models.NMF import NMF\n",
    "\n",
    "\n",
    "from scripts.get_data import download_2_data_sets, ratings_to_train_test\n",
    "from scripts.get_2_other_data import get_2_other_datasets, secondary_to_train_test\n",
    "from utils.evaluate import evaluate_model\n",
    "from utils.loading_utils import load_model, save_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Visualization Stuff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec - AutoEncoders Meet Collaborative Filtering - PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"toc\"></a>\n",
    "## Table of Content\n",
    "1. [Introduction](#introduction)\n",
    "1. [Conclusions](#conclusions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"introduction\"></a>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will review a collaborative filtering approach using autoencoders, as suggested by Sedhain et al, in their 2015 paper \"AutoRec: Autoencoders Meet Collaborative Filtering\".\n",
    "\n",
    "We will then introduce several improvements and asses them.\n",
    "\n",
    "[Table of content](#toc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "is_default_dataset = True\n",
    "if is_default_dataset:\n",
    "    download_2_data_sets()\n",
    "else:\n",
    "    get_2_other_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if is_default_dataset:\n",
    "    train_loader, val_loader = ratings_to_train_test(1,0, 1,10)\n",
    "else:\n",
    "    train_loader, val_loader = secondary_to_train_test(1,0, 1,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Go to:  [TensorBoard](http://localhost:6006)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "models_dict = {} # (model,ephoc,lr): loss\n",
    "models_state = {} # (model,ephoc,lr): model.state_dict()\n",
    "models = [AutoRecBase, VarAutoRec, NMF]\n",
    "lrs = [0.0005,0.001,0.002,0.004]\n",
    "activations = [nn.PReLU, nn.Sigmoid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the original paper:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "latent_dims = [10, 20, 40, 80, 100, 200, 300, 400, 500]\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 100, 1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | encoder   | Linear  | 92.7 K\n",
      "1 | act_1     | PReLU   | 1     \n",
      "2 | decoder   | Linear  | 96.4 K\n",
      "3 | act_2     | PReLU   | 1     \n",
      "4 | loss_func | MSELoss | 0     \n",
      "--------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57c2500faa7b4a4fa07adcf3c7000efa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3469ec474d4546e1a8e036a8472a583b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cc03b9f5f3646d4b4ad32f5a000baec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obj/AutoRecBase_PReLU_10_0.0005_0.001_True_model_dict.ckpt']\n"
     ]
    }
   ],
   "source": [
    "should_train = True\n",
    "model_paths = []\n",
    "if should_train:\n",
    "    for model_class in models:\n",
    "        for activation in activations:\n",
    "            for lr in lrs:\n",
    "                for latent in latent_dims:\n",
    "                    for λ in lambdas:\n",
    "                        model = model_class(number_of_items=3706,\n",
    "                                            hidden_size=25,\n",
    "                                            activation_function_1=activation,\n",
    "                                            activation_function_2=activation,\n",
    "                                            loss=nn.MSELoss(reduction='none'),\n",
    "                                            λ=λ,\n",
    "                                            lr=lr)\n",
    "                        # training\n",
    "                        trainer = pl.Trainer(gpus=0, max_epochs=1, checkpoint_callback=False)\n",
    "                        trainer.fit(model,train_loader, val_loader)\n",
    "\n",
    "                        model_path = save_model(model_class=model_class,\n",
    "                                   trainer=trainer,\n",
    "                                   activation=activation,\n",
    "                                   hidden_size=latent,\n",
    "                                   lr=lr,\n",
    "                                   λ=λ,\n",
    "                                   is_default_dataset=is_default_dataset)\n",
    "                        model_paths.append(model_path)\n",
    "                        break\n",
    "                    break\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "print(model_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoRecBase(\n",
      "  (encoder): Linear(in_features=3706, out_features=25, bias=True)\n",
      "  (act_1): PReLU(num_parameters=1)\n",
      "  (decoder): Linear(in_features=25, out_features=3706, bias=True)\n",
      "  (act_2): PReLU(num_parameters=1)\n",
      "  (loss_func): MSELoss()\n",
      ")\n",
      "tensor([[2366, 3205, 1030,  ..., 1721, 2723,  803],\n",
      "        [2366, 3205, 1030,  ..., 1721, 2723,  803],\n",
      "        [2366, 3205, 1030,  ..., 1721, 2723,  803],\n",
      "        ...,\n",
      "        [2366, 3205, 1030,  ..., 1721, 2723,  803],\n",
      "        [2366, 3205, 1030,  ..., 1721, 2723,  803],\n",
      "        [3205, 2366, 1030,  ..., 2723, 1127,  803]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m model \u001B[38;5;241m=\u001B[39m load_model(model_class\u001B[38;5;241m=\u001B[39mmodel_class,\n\u001B[1;32m     11\u001B[0m                    activation\u001B[38;5;241m=\u001B[39mactivation,\n\u001B[1;32m     12\u001B[0m                    hidden_size\u001B[38;5;241m=\u001B[39mlatent,\n\u001B[1;32m     13\u001B[0m                    lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m     14\u001B[0m                    λ\u001B[38;5;241m=\u001B[39mλ,\n\u001B[1;32m     15\u001B[0m                    is_default_dataset\u001B[38;5;241m=\u001B[39mis_default_dataset)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m K \u001B[38;5;129;01min\u001B[39;00m Ks:\n\u001B[0;32m---> 17\u001B[0m     (hits, ndcgs, mrrs) \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mK\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     models_eval_dict[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, activation, latent, λ, lr, K, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHR\u001B[39m\u001B[38;5;124m\"\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(hits)]\n\u001B[1;32m     19\u001B[0m     models_eval_dict[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, activation, latent, λ, lr, K, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNDCG\u001B[39m\u001B[38;5;124m\"\u001B[39m,np\u001B[38;5;241m.\u001B[39mmean(ndcgs)]\n",
      "File \u001B[0;32m~/Developer/AutoRec/utils/evaluate.py:17\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model, test_loader, K)\u001B[0m\n\u001B[1;32m     15\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(model(X)\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mdetach())\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(predictions)\n\u001B[0;32m---> 17\u001B[0m (hr, ndcg, mrr) \u001B[38;5;241m=\u001B[39m \u001B[43meval_one_rating\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mK\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m hits\u001B[38;5;241m.\u001B[39mappend(hr)\n\u001B[1;32m     20\u001B[0m ndcgs\u001B[38;5;241m.\u001B[39mappend(ndcg)\n",
      "File \u001B[0;32m~/Developer/AutoRec/utils/evaluate.py:29\u001B[0m, in \u001B[0;36meval_one_rating\u001B[0;34m(predictions)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21meval_one_rating\u001B[39m(predictions):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Evaluate top rank list\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     hr \u001B[38;5;241m=\u001B[39m get_hit_ratio(predictions)\n\u001B[0;32m---> 29\u001B[0m     ndcg \u001B[38;5;241m=\u001B[39m \u001B[43mget_ndcg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     mrr \u001B[38;5;241m=\u001B[39m get_mrr(predictions)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hr, ndcg, mrr\n",
      "File \u001B[0;32m~/Developer/AutoRec/utils/evaluate.py:41\u001B[0m, in \u001B[0;36mget_ndcg\u001B[0;34m(ranklist)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(ranklist)):\n\u001B[1;32m     40\u001B[0m     item \u001B[38;5;241m=\u001B[39m ranklist[i]\n\u001B[0;32m---> 41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m math\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m math\u001B[38;5;241m.\u001B[39mlog(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "models_eval_dict = {}\n",
    "Ks = [5, 10]\n",
    "i = 0\n",
    "\n",
    "for model_class in models:\n",
    "    for activation in activations:\n",
    "        for lr in lrs:\n",
    "            for latent in latent_dims:\n",
    "                for λ in lambdas:\n",
    "                    model = load_model(model_class=model_class,\n",
    "                                       activation=activation,\n",
    "                                       hidden_size=latent,\n",
    "                                       lr=lr,\n",
    "                                       λ=λ,\n",
    "                                       is_default_dataset=is_default_dataset)\n",
    "                    for K in Ks:\n",
    "                        (hits, ndcgs, mrrs) = evaluate_model(model, test_loader=val_loader, K=K)\n",
    "                        models_eval_dict[f\"row_{i}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"HR\", np.mean(hits)]\n",
    "                        models_eval_dict[f\"row_{i+1}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"NDCG\",np.mean(ndcgs)]\n",
    "                        models_eval_dict[f\"row_{i+2}\"] = [type(model).__name__, activation, latent, λ, lr, K, \"MRR\",np.mean(mrrs)]\n",
    "                        i += 3\n",
    "                        break\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [model, activation, latent_dim, lambda, lr, topk, metric, score]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>activation</th>\n      <th>latent_dim</th>\n      <th>lambda</th>\n      <th>lr</th>\n      <th>topk</th>\n      <th>metric</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"model\", \"activation\", \"latent_dim\", \"lambda\", \"lr\",\"topk\",\"metric\",\"score\"]\n",
    "eval_df = pd.DataFrame.from_dict(models_eval_dict, orient='index', columns=columns)\n",
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(60, 20)\n",
    "\n",
    "for i, metric in enumerate(['HR', 'NDCG', 'MRR']):\n",
    "    sns.barplot(data=eval_df[eval_df[\"metric\"] == metric], x=\"model\", y=\"score\", hue=\"topk\", ax=axs[i], orient='v').set(title=metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}